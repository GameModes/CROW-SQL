{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m36n6CinC3Gv",
        "scrolled": true
      },
      "source": [
        "# Connecting LLM with Agent on SQL Databases (using mostly google cloud)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information for new Colab users before running the project: \\\n",
        "1. Colab uses Virtual Machines (VM) to run Python Scripts. You can activate one by pressing the Connect button right top corner. It is currently set on using Standard CPU and GPU and High Ram, but you can customize it if you want.\n",
        "2. In Colab you can Collapse and Extend cells to improve the viewablity. The next block contains 2 code cells of downloading the libraries. You can simply press the play icon if you hover over the \"2 cells hidden\" text to automatically run the code after one another without looking at the code.\n",
        "\n",
        "Information about the project beforehand: \\\n",
        "1. After the Libraries cell block, you have the LLM Retrieval cell block. This block lets you choose whether you prefer to activate Gemini's (vertex_llm) and/or OpenAI's model (OpenAIllm). You need to read this code part a bit yourself to understand it properly. Like Gemini needs your account info to access Vertex models, while OpenAI uses a simple API key.\n",
        "2. After the LLM Retrieval cell block, you have the Database Connection cell block. This extracts the database files out of (in this case) Google cloud. Each database is stored together in a single variable using function \"extract_databases_from_gcs\". You can use either Bird-bench or Spider to benchmark the LLMs. (You can only use one to place in the variable \"test_databases\")\n",
        "3. After the Database Connection cell block, you have the Benchmarking cell block. Here you can configure the parameters for both the agents and the LLM (be careful to use correct wording for each benchmark). Afterwards each agent is configured (no need to change anything there if you don't want to) and some extra functions to properly deal with some data structures like in the \"Loading function\" cell. After that the \"running\" cell shows live how the process is ran. If you want to see what each agent thinks, you can turn on the \"verbose\" parameter in the configure agent function. Currently only the thinking process of the manager agent is turned on.\n",
        "4. During the running process of the \"running\" cell, after each database is finished its output is stored in the folder that is indicated by the variable \"output_folder\" (see cell after \"Benchmarking\" cell block) like \"bird-bench/benchmarks/senior_geminiv5/california_schools.json\". Currently this is stored within Google Cloud Console -> Buckets -> Dashboardllmbucket -> \"output folder\".\n",
        "5. The naming of the google cloud folders are based off the parameters. A name like \"refiner_geminiv3(5)\" uses All agents + Gemini + 3 Query amount + 5 Few shots. A name like \"senior_geminiv5\" uses Manager, Database and Senior agent + Gemini + 5 Query Amount.\n"
      ],
      "metadata": {
        "id": "KG7gQSjrRgIV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLEbhOsaC3G1"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WktMJ3_C3G3",
        "outputId": "257cab81-1c89-49b7-aa2b-144d415f5ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic==2.9.2 in /usr/local/lib/python3.11/dist-packages (2.9.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2) (4.14.1)\n",
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.11/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2025.7.14)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.28)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.69)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.96.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.9.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.69)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.23.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_experimental) (0.3.27)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.28 in /usr/local/lib/python3.11/dist-packages (from langchain_experimental) (0.3.69)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.6)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.9.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.8)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.28->langchain_experimental) (2.23.4)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.69)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: langchain_google_vertexai in /usr/local/lib/python3.11/dist-packages (2.0.27)\n",
            "Requirement already satisfied: bottleneck<2.0.0,>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (1.4.2)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.97.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (1.104.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.19.0)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.4.1)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.67 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.3.69)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.6 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.11.0)\n",
            "Requirement already satisfied: pyarrow<20.0.0,>=19.0.1 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (19.0.1)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.9 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (2.9.2)\n",
            "Requirement already satisfied: validators<1,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_vertexai) (0.35.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck<2.0.0,>=1.4.2->langchain_google_vertexai) (2.0.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (25.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (3.34.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.8.5.post1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.26.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (4.14.1)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.32.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (1.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (0.16.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (0.4.6)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain_google_vertexai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.9->langchain_google_vertexai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (0.14.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.28.0->langchain_google_vertexai) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3.67->langchain_google_vertexai) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.18.0->langchain_google_vertexai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.97.0->langchain_google_vertexai) (1.17.0)\n",
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.11/dist-packages (2.9.10)\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,943 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,467 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,151 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,155 kB]\n",
            "Fetched 18.4 MB in 1s (14.3 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package google-cloud-sdk\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.26.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.9.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.9.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.4.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.11/dist-packages (1.104.0)\n",
            "Requirement already satisfied: shapely<2 in /usr/local/lib/python3.11/dist-packages (1.8.5.post1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (3.34.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.26.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.9.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.14.1)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (4.9.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic==2.9.2\n",
        "!pip install transformers==4.41.2\n",
        "!pip install langchain-openai\n",
        "!pip install langchain-community\n",
        "!pip install langchain_experimental\n",
        "!pip install -U langchain-google-genai\n",
        "!pip install langchain_google_vertexai\n",
        "!pip install google-cloud-language>=2.9.1\n",
        "!pip install psycopg2\n",
        "!sudo apt-get update && sudo apt-get install google-cloud-sdk\n",
        "!pip install --upgrade google-genai\n",
        "!pip install -U google-cloud-aiplatform \"shapely<2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDFi41KZC3G8"
      },
      "outputs": [],
      "source": [
        "# =======================\n",
        "# Standard Library Imports\n",
        "# =======================\n",
        "import ast\n",
        "import base64\n",
        "import getpass\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sqlite3\n",
        "import tempfile\n",
        "import time\n",
        "import uuid\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from operator import itemgetter\n",
        "from sqlite3 import OperationalError\n",
        "from typing import (\n",
        "    TYPE_CHECKING,\n",
        "    Any,\n",
        "    Annotated,\n",
        "    Dict,\n",
        "    List,\n",
        "    Literal,\n",
        "    Optional,\n",
        "    Sequence,\n",
        "    Union,\n",
        "    cast,\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# Suppress Warnings\n",
        "# =======================\n",
        "from sqlalchemy.exc import SAWarning\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    message=\".*Cannot correctly sort tables; there are unresolvable cycles.*\",\n",
        "    category=SAWarning,\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# Third-Party Library Imports\n",
        "# =======================\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import sentencepiece\n",
        "import sqlparse\n",
        "import torch\n",
        "from IPython.display import Image, display\n",
        "from pydantic import BaseModel, Field\n",
        "from sqlparse.sql import TokenList\n",
        "\n",
        "# =======================\n",
        "# Google Cloud & VertexAI\n",
        "# =======================\n",
        "from google import genai\n",
        "from google.cloud import storage\n",
        "from google.colab import auth\n",
        "from google.genai import types\n",
        "import vertexai\n",
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "# =======================\n",
        "# HuggingFace Transformers\n",
        "# =======================\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Conversation,\n",
        "    LlamaForCausalLM,\n",
        "    LlamaTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    pipeline,\n",
        ")\n",
        "\n",
        "# =======================\n",
        "# LangChain Core\n",
        "# =======================\n",
        "from langchain.agents import AgentExecutor, AgentType, create_tool_calling_agent, tool\n",
        "from langchain.agents.agent import (\n",
        "    RunnableAgent,\n",
        "    RunnableMultiActionAgent,\n",
        ")\n",
        "from langchain.chains import create_sql_query_chain\n",
        "from langchain.llms.base import BaseLLM\n",
        "from langchain.memory import ChatMessageHistory\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain.tools.base import Tool\n",
        "\n",
        "# LangChain Core Modules\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.messages import AIMessage as CoreAIMessage, SystemMessage, ToolMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    RunnablePassthrough,\n",
        "    RunnableWithFallbacks,\n",
        "    chain,\n",
        ")\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.tools import tool as core_tool\n",
        "\n",
        "# =======================\n",
        "# LangChain Community\n",
        "# =======================\n",
        "from langchain_community.agent_toolkits import SQLDatabaseToolkit, create_sql_agent\n",
        "from langchain_community.agent_toolkits.sql.prompt import (\n",
        "    SQL_FUNCTIONS_SUFFIX,\n",
        "    SQL_PREFIX,\n",
        "    SQL_SUFFIX,\n",
        ")\n",
        "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit as CommunitySQLToolkit\n",
        "from langchain_community.tools.sql_database.tool import (\n",
        "    InfoSQLDatabaseTool,\n",
        "    ListSQLDatabaseTool,\n",
        "    QuerySQLCheckerTool,\n",
        ")\n",
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "\n",
        "from langchain_community.utilities import SQLDatabase as CommunitySQLDatabase\n",
        "from langchain_openai import ChatOpenAI\n",
        "# =======================\n",
        "# Typing Extensions\n",
        "# =======================\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLT5lRVGC3HB"
      },
      "source": [
        "## LLM Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnRJukw4FOCN"
      },
      "source": [
        "### Vertex AI models\n",
        "gemini-2.0-flash-001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuxtXbcX4Mcn",
        "outputId": "dd5b18ac-8bac-47ae-ca46-90f39de2b8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication done!\n"
          ]
        }
      ],
      "source": [
        "'''Option 1: using google authentication (requires colab user to have access with google cloud project for gemini)'''\n",
        "auth.authenticate_user()\n",
        "\n",
        "'''Option 2: using a key file'''\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# key_path = list(uploaded.keys())[0] #gets the uploaded file name.\n",
        "# print(key_path)\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path\n",
        "\n",
        "print('''Authentication done!''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUQQgB3TR2qT",
        "outputId": "4018a879-6a41-43d7-d3b0-c4a249e5c6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Gemini model as \"vertex_llm\"\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"dashboard-llm-454014\"  # Replace with your project ID\n",
        "REGION = \"europe-west1\"  # Use the region where your model is available.\n",
        "\n",
        "# Initialize Vertex AI (using default credentials)\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "vertex_llm = ChatVertexAI(\n",
        "    model=\"gemini-2.0-flash-001\", #could be any model, preferably gemini-2.0-flash-001 for good and cheapest results\n",
        "    temperature=0,\n",
        "    max_tokens=2048,\n",
        "    max_retries=16,\n",
        "    stop=None,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "print('''Initialized Gemini model as \"vertex_llm\"''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIUuS_DgFXvf"
      },
      "outputs": [],
      "source": [
        "# def custom_token_encoder(text: str) -> List[int]:\n",
        "#     \"\"\"Custom function to encode text into token IDs.\"\"\"\n",
        "#     return [ord(char) for char in text]  # Example encoding (replace with actual tokenizer)\n",
        "\n",
        "# def count_tokens(text: str) -> int:\n",
        "#     \"\"\"Counts the number of tokens in a given text.\"\"\"\n",
        "#     return len(custom_token_encoder(text))  # Use your tokenizer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ireR1GVC3HD"
      },
      "source": [
        "### OpenAI models\n",
        "\"gpt-4o\", \"gpt-4\", \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt5WqhlrJZTi"
      },
      "outputs": [],
      "source": [
        "openai_key = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYzGHWfYC3HF"
      },
      "source": [
        "#### Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFJmt6p6C3HG"
      },
      "outputs": [],
      "source": [
        "def _set_env(key: str, value: str):\n",
        "    if key not in os.environ:\n",
        "        os.environ[key] = value\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\", openai_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmWLfwkmC3HJ"
      },
      "source": [
        "#### Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dw0vuClC3HL"
      },
      "outputs": [],
      "source": [
        "OpenAIllm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=openai_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bp4c2dKpL6Yv",
        "outputId": "f0ea799d-d21a-4ddb-e375-0ed4739dc4e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Optionally testing the LLM'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''Optionally testing the LLM'''\n",
        "# OpenAIllm.invoke(\"Hi, what is your name?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR4tGfAvC3Hk"
      },
      "source": [
        "## Database connection\n",
        "This Demo uses data from buckets within the google cloud console (=gcs).\\\n",
        "If you will only use ChatGPT, I would advice using google drive to integrate the data within the project instead of google cloud console"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCtuYvlZvcLx"
      },
      "outputs": [],
      "source": [
        "def extract_databases_from_gcs(bucket_name, dataset_folder):\n",
        "    databases = {}\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "\n",
        "    blobs = client.list_blobs(bucket_name, prefix=dataset_folder)\n",
        "\n",
        "    for blob in blobs:\n",
        "\n",
        "        file_name = blob.name.split(\"/\")[-1] #get filename\n",
        "        folder_name = blob.name.split(\"/\")[-2] #get folder name\n",
        "\n",
        "        if file_name.endswith(\".DS_Store\"):\n",
        "            continue\n",
        "        elif file_name.endswith(\".json\"):\n",
        "            continue\n",
        "        elif file_name.endswith(\".sqlite\"): #ensure the sqlite file is the correct one.\n",
        "            # Download the SQLite file content into memory\n",
        "            sqlite_data = blob.download_as_bytes()\n",
        "\n",
        "            # Create a temporary file\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".sqlite\") as temp_sqlite_file:\n",
        "                temp_sqlite_file.write(sqlite_data)\n",
        "                temp_file_path = temp_sqlite_file.name\n",
        "\n",
        "            # Create a URI for the temporary SQLite database\n",
        "            db_uri = f\"sqlite:///{temp_file_path}\"\n",
        "\n",
        "            # Create the SQLDatabase object\n",
        "            db = SQLDatabase.from_uri(db_uri)\n",
        "\n",
        "            databases[folder_name] = db\n",
        "\n",
        "    return databases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFfzZkHZZcgo"
      },
      "source": [
        "### Bird-Bench Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDtFgQPKvhbw",
        "outputId": "d4550dee-ba09-4307-a8ec-65f9996baf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['california_schools', 'card_games', 'codebase_community', 'debit_card_specializing', 'european_football_2', 'financial', 'formula_1', 'student_club', 'superhero', 'thrombosis_prediction', 'toxicology']\n"
          ]
        }
      ],
      "source": [
        "bucket_name = \"dashboardllmbucket\"  # Replace with your bucket name\n",
        "test_dataset_folder = \"bird-bench/dev/dev_databases\"\n",
        "\n",
        "test_databases = extract_databases_from_gcs(bucket_name, test_dataset_folder)\n",
        "\n",
        "test_databases_names = list(test_databases.keys())\n",
        "\n",
        "print(test_databases_names) #the code is build that it loops through this list of database names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quVJypV7cSmF"
      },
      "source": [
        "### Spider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzW5xdaUcSmG"
      },
      "outputs": [],
      "source": [
        "# bucket_name = \"dashboardllmbucket\"  # Replace with your bucket name\n",
        "# test_dataset_folder = \"spider/dev/database\"\n",
        "\n",
        "# test_databases = extract_databases_from_gcs(bucket_name, test_dataset_folder)\n",
        "\n",
        "# test_databases_names = list(test_databases.keys())\n",
        "\n",
        "# print(test_databases_names) #the code is build that it loops through this list of database names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4daVtb3AjqXP"
      },
      "source": [
        "## Benchmarking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wz9XuPTDjpjH"
      },
      "outputs": [],
      "source": [
        "# Change which agent should have which LLM as a core. (Potentially you can make them all gemini/vertex or all gpt)\n",
        "databasellm = vertex_llm\n",
        "refinerllm = vertex_llm\n",
        "seniorllm = vertex_llm\n",
        "managerllm = vertex_llm\n",
        "\n",
        "# Output path for JSON files (currently is also google cloud)\n",
        "bucket_name = \"dashboardllmbucket\"\n",
        "\n",
        "output_folder = \"bird-bench/benchmarks/senior_geminiv5\" #bird-bench or spider (the folder is automatically created if it doesn't exist)\n",
        "question_path = \"bird-bench/dev/dev.json\" #bird-bench or spider\n",
        "few_shot_path = \"bird-bench/dev/dev.json\" #bird-bench or spider\n",
        "\n",
        "# output_folder = \"spider/benchmarks/senior_geminiv5\" #bird-bench or spider (the folder is automatically created if it doesn't exist)\n",
        "# question_path = \"spider/dev/dev.json\" #bird-bench or spider\n",
        "# few_shot_path = \"spider/dev/dev.json\" #bird-bench or spider\n",
        "\n",
        "few_shot_amount = 10\n",
        "query_table_name = \"SQL\" #JSON table name where the correct SQL is stored (SQL for bird, query for spider)\n",
        "query_amount = 5\n",
        "\n",
        "# All optional agents to potentially improve the usage of the database llm agent\n",
        "use_manager_agent = True #helps organize all the agents and improve the semantic understanding of the question\n",
        "use_senior_agent = True #helps indicate which columns/tables it should use (requires manager agent to be True)\n",
        "use_refiner_agent = True #helps refine the queries if all are incorrect (requires manager agent to be True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQ-AynmOndr"
      },
      "source": [
        "#### Configure Database agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxCyR_L0k4K7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def configure_databasellmv2(database_name, bucket_name, few_shot_path, few_shot_amount=3, query_amount=1, query_table_name='query'):\n",
        "  sql_query_store = []\n",
        "  toolkit = SQLDatabaseToolkit(db=db, llm=databasellm)\n",
        "  list_sql_database_tool = toolkit.get_tools()[2]\n",
        "\n",
        "  info_sql_database_tool = toolkit.get_tools()[1]\n",
        "  info_sql_database_tool.description = (\n",
        "        \"Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. \"\n",
        "        f\"Be sure that the tables actually exist by calling {list_sql_database_tool.name} first! \"\n",
        "        \"Example Input: table1, table2, table3\"\n",
        "    )\n",
        "\n",
        "  query_sql_database_tool = toolkit.get_tools()[0]\n",
        "  query_sql_database_tool.description= (\n",
        "              \"Input to this tool is a detailed and correct SQL query, output is a \"\n",
        "              \"result from the database. If the query is not correct, an error message \"\n",
        "              \"will be returned. If an error is returned, rewrite the query, check the \"\n",
        "              \"query, and try again. If you encounter an issue with Unknown column \"\n",
        "              f\"'xxxx' in 'field list', use {info_sql_database_tool.name} \"\n",
        "              \"to query the correct table fields.\"\n",
        "          )\n",
        "\n",
        "  databasellm_tools = [\n",
        "      list_sql_database_tool,\n",
        "      info_sql_database_tool,\n",
        "      query_sql_database_tool,\n",
        "  ]\n",
        "\n",
        "  # Load training data from GCS\n",
        "  training_data = load_json_from_gcs(bucket_name, few_shot_path)\n",
        "\n",
        "  # Creating prompt given parameters\n",
        "  database_train = [entry for entry in training_data if entry.get(\"db_id\") == database_name]\n",
        "  prompt = f\"\"\"You are an AI SQL agent specializing in generating and executing **syntactically correct SQL queries** in SQLite language.\"\"\"\n",
        "\n",
        "  #Determining in prompt how many queries it should make\n",
        "  if query_amount == 1:\n",
        "    prompt += f\"\"\"\n",
        "    Return **only** a single final SQL querywithout explanations, reasoning, or extra textthat can be valid answers to the prompt.\"\"\"\n",
        "  else:\n",
        "    prompt += f\"\"\"\n",
        "    Return **only** {query_amount} different final SQL querieswithout explanations, reasoning, or extra textthat can be valid answers to the prompt.\"\"\"\n",
        "\n",
        "  if few_shot_amount != 0:\n",
        "    few_shot_examples = \"\\n\".join(\n",
        "        [f\"Question: {ex['question']}\\nSQL: {ex[query_table_name]}\" for ex in database_train[:few_shot_amount]]\n",
        "    )\n",
        "    prompt += f\"\"\"\n",
        "  ### **Database Knowledge**\n",
        "  Examples of correct queries based on the database structure:\n",
        "    {few_shot_examples}\"\"\"\n",
        "\n",
        "  prompt += f\"\"\"\n",
        "  ### **SQL Generation Rules**\"\"\"\n",
        "  #Determining in prompt how many queries it should make\n",
        "  if query_amount == 1:\n",
        "    prompt += f\"\"\"\n",
        "    - **Only return a single SQL queryno explanations.**\n",
        "    \"\"\"\n",
        "  else:\n",
        "    prompt += f\"\"\"\n",
        "  - **Only return {query_amount} SQL queriesno explanations.**\n",
        "  - **Each query MUST use a different primary table in the SELECT clause if the Table usage is the same.**\n",
        "  - Also fluctuate the where clause generation of each query, by using \"LIKE '%word%'\" instead of \"= 'thisisalongword'.\n",
        "  - Also fluctuate the generation of each query, for between tables and without or without GROUP BY\n",
        "  - Use **different aggregation methods** (COUNT, SUM, AVG, etc.).\n",
        "  - Use if applicable **different order by methods** (ABS, ASC, DESC, etc.) if not mentioned vaguely in the prompt.\"\"\"\n",
        "\n",
        "  prompt += f\"\"\"\n",
        "  - **If the query can be rewritten using a different table as the base table, do so.**\n",
        "  - **Test each query using query_sql_database_tool tool if incorrect, rewrite the query.**\n",
        "  - **If not explicitly said, also experiment with or without using DISTINCT**.\n",
        "  - Tools are for internal use to gather information before writing SQL  not part of the SQL query itself.\n",
        "  - **When the question asks for the \"most\" or \"least\" amount paid, or any similar question related to totals or overall sums, ensure that you use the SUM() aggregate function and a GROUP BY clause to calculate the total amount for each customer, entity or group.**\n",
        "\n",
        "  ### **Tools Available**\n",
        "  Use the following tools as needed:\n",
        "  - `tool_list_tables`: Lists table names in the database.\n",
        "  - `tool_info_schema`: Shows table schema and sample rows.\n",
        "  - `tool_run_query`: Executes SQL queries to get results. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use `info_sql_database_tool` to query the correct table fields\n",
        "\n",
        "  ##  Do NOT misuse tools inside SQL queries\n",
        "   NEVER include tool names (e.g., `tool_list_tables`, `tool_info_schema`, `tool_run_query`) inside a SQL statement.\n",
        "  - They are NOT SQL functions.\n",
        "  - NEVER write `SELECT tool_list_tables()` or anything similar.\n",
        "  - These tools are **used before writing SQL** to gather information about the database structure.\n",
        "\n",
        "  ## External Knowledge\n",
        "  - Bonding/bonded also means connected\n",
        "  - When asked about an object that doesn't have an exact column about it (such as \"atoms\") try to use the ID column of it (like column atom_id from atom or atom_id from connected or atom_id2 from connected)\n",
        "  - When asked find object x from y which has object z, also mention object y in the SELECT column.\n",
        "  - When you hesitate between objects to SELECT, use all 2 or 3. Rather have too much information than less.\n",
        "  - Given a question/prompt with \"between\" place it in the query with the appropriate values. Like: Prompt:Among the molecules between TR004 to TR010, how many of them has single bonds? Answer: SELECT COUNT(DISTINCT T.molecule_id) FROM bond AS T WHERE T.molecule_id BETWEEN 'TR004' AND 'TR010' AND T.bond_type = '-'\n",
        "  - When given answers with a lot of NONE values, try to make a query that says to show no \"NONE\" or aren't null\n",
        "\n",
        "  - Before writing any SQL, ALWAYS first:\n",
        "    1. Use `tool_list_tables` to get the list of available tables.\n",
        "    2. Then use `tool_info_schema` on relevant tables to view columns and relationships.\n",
        "    3. Only after gathering table and schema info, generate valid SQL using actual table/column names.\n",
        "\n",
        "  ### **Response Format**\n",
        "  \"\"\"\n",
        "\n",
        "  if query_amount == 1:\n",
        "    prompt += f\"\"\"Your response **must only contain the final SQL query**, without any explanation or reasoning.\"\"\"\n",
        "  else:\n",
        "    prompt += f\"\"\"Your response **must only contain the final SQL queries**, without any explanation or reasoning.\"\"\"\n",
        "\n",
        "  prompt += f\"\"\"\n",
        "     Valid SQL starts with SELECT, INSERT, UPDATE, etc.\n",
        "     Invalid SQL includes non-SQL tool names like `tool_list_tables()`.\n",
        "    \"\"\"\n",
        "  # databasellm_prompt = PromptTemplate(template=prompt, input_variables=[\"input\"])\n",
        "  messages = [prompt, HumanMessagePromptTemplate.from_template(\"{input}\"), AIMessage(content=SQL_FUNCTIONS_SUFFIX), MessagesPlaceholder(variable_name=\"agent_scratchpad\")]\n",
        "\n",
        "  databasellm_prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "  runnable = create_tool_calling_agent(databasellm, databasellm_tools, databasellm_prompt)  # type: ignore\n",
        "\n",
        "  agent = RunnableMultiActionAgent(runnable=runnable,input_keys_arg=[\"input\"], return_keys_arg=[\"output\"])\n",
        "\n",
        "  databasellm_agent = AgentExecutor(\n",
        "          name=\"SQL Agent Executor\",\n",
        "          agent=agent,\n",
        "          tools=databasellm_tools,\n",
        "          verbose=False,\n",
        "          max_iterations=40,\n",
        "          max_execution_time=None,\n",
        "\n",
        "\n",
        "      )\n",
        "  print(\"Database Agent created!\")\n",
        "  return databasellm_agent, list_sql_database_tool, info_sql_database_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVxc9NzGzTr6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR_ePR3D0E_J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0P8zZzEkMVA"
      },
      "source": [
        "#### Configure Manager Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxowbiaiK2-2"
      },
      "outputs": [],
      "source": [
        "def limiting_queries(query):\n",
        "    if \"LIMIT\" not in query.upper() and \"COUNT\" not in query.upper():\n",
        "        return query + \" LIMIT 8\"\n",
        "    else:\n",
        "        return query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRM6hZMs2TzY"
      },
      "outputs": [],
      "source": [
        "def limiting_queries(query: str) -> str:\n",
        "    \"\"\"Applies LIMIT only if it's a non-aggregate SELECT query.\"\"\"\n",
        "    import re\n",
        "    is_aggregate = bool(re.search(r'\\b(COUNT|SUM|AVG|MIN|MAX)\\b', query, re.IGNORECASE))\n",
        "    if \"SELECT\" in query.upper() and not is_aggregate and \"LIMIT\" not in query.upper():\n",
        "        optimized_query = query.rstrip(\";\") + \" LIMIT 50;\"\n",
        "    else:\n",
        "        optimized_query = query\n",
        "    return optimized_query\n",
        "\n",
        "def extract_tables_from_queries(queries: List[str]) -> List[str]:\n",
        "    \"\"\"Extracts table names from a list of SQL queries.\"\"\"\n",
        "    import re\n",
        "    tables = set()\n",
        "    for query in queries:\n",
        "        found_tables = re.findall(r\"\\bFROM\\s+([\\w_]+)\", query, re.IGNORECASE)\n",
        "        tables.update(found_tables)\n",
        "        found_joins = re.findall(r\"\\bJOIN\\s+([\\w_]+)\", query, re.IGNORECASE)\n",
        "        tables.update(found_joins)\n",
        "    return list(tables)\n",
        "\n",
        "def is_suspicious_result(query, result):\n",
        "    # Flatten the result\n",
        "    flat = [item for row in result for item in row]\n",
        "\n",
        "    # Case: percentage query returns 0 or None\n",
        "    if \"percentage\" in query.lower() or \"percent\" in query.lower():\n",
        "        if all(val in [None, 0, 0.0] for val in flat):\n",
        "            return True\n",
        "\n",
        "    # Case: ID list query returns only nulls\n",
        "    if \"id\" in query.lower() and all(val in [None, \"\"] for val in flat):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def is_valid_result(result):\n",
        "    try:\n",
        "        # Flatten nested tuples like [('0.66',)] to just values\n",
        "        flat = [item for row in result for item in row]\n",
        "        for val in flat:\n",
        "            if isinstance(val, (int, float)) and val > 0:\n",
        "                return True\n",
        "            if isinstance(val, str) and val.strip() not in ('0', '', 'null', 'None'):\n",
        "                return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "468ISr-pkLqS"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def create_manager_agentv3(databasellm_agent, seniorllm_agent, refinerllm_agent, list_sql_database_tool, info_sql_database_tool):\n",
        "  # Store errors per session\n",
        "  error_history_store = defaultdict(list)\n",
        "\n",
        "  @tool\n",
        "  def generate_sql_query_tool(prompt: str) -> list:\n",
        "      \"\"\"\n",
        "      This tool generates SQL queries based on a user's natural language input.\n",
        "      Optionally it can invoke the seniorllm_agent for more information.\n",
        "      Afterwards each query is executed in the execute_sql_query_tool function.\n",
        "      Optionally within the execute_sql_query_tool function, the refinerllm_agent can be used to refine the queries.\n",
        "\n",
        "      Args:\n",
        "          prompt (str): The user's natural language input.\n",
        "\n",
        "      Returns:\n",
        "          list: A list of the results of the SQL queries, which you can use to answer the prompt/question.\n",
        "      \"\"\"\n",
        "      extended_prompt = f\"\"\"\n",
        "      Based on the following question, generate **a single** accurate SQL query given the prompt. **ALWAYS** assume that it is possible to answer the given question with given prompt information with the database.\n",
        "\n",
        "      **User Question:** {prompt}\n",
        "      \"\"\"\n",
        "\n",
        "      if seniorllm_agent != None:\n",
        "        senior_response = seniorllm_agent.invoke(prompt)['output']\n",
        "\n",
        "        # Extract tables\n",
        "        tables_match = re.search(r\"\\*\\*Tables:\\*\\* `(.*?)`\", senior_response, re.DOTALL)\n",
        "        tables = tables_match.group(1).split(\", \") if tables_match else []\n",
        "\n",
        "        # Extract relevant columns per table\n",
        "        columns_dict = {}\n",
        "        column_matches = re.findall(r\"- `(\\w+)`  (.*?)\\n\", senior_response)\n",
        "\n",
        "        for table, columns in column_matches:\n",
        "            column_list = [col.strip() for col in columns.split(\",\")]\n",
        "            columns_dict[table] = column_list\n",
        "\n",
        "        # Extract explanation\n",
        "        explanation_match = re.search(r\"\\*\\*Explanation of relevance:\\*\\*\\n(.*)\", senior_response, re.DOTALL)\n",
        "        explanation = explanation_match.group(1).strip() if explanation_match else \"\"\n",
        "\n",
        "        structured_response = {\n",
        "            \"tables\": tables,\n",
        "            \"columns\": columns_dict,\n",
        "            \"explanation\": explanation}\n",
        "\n",
        "        relevant_info_str = str(structured_response) if structured_response else \"No relevant info found.\"\n",
        "        extended_prompt += f\"\"\"\n",
        "      **Relevant Info:** {relevant_info_str}\n",
        "      \"\"\"\n",
        "      extended_prompt += f\"\"\"\n",
        "      - Use only the tables and columns listed as relevant.\n",
        "      - Include all user-requested fields.\n",
        "      - Use JOINs when combining data from multiple tables.\n",
        "      - Add filters (WHERE, LIKE, IN) if needed to fulfill the user's question.\n",
        "      - Use aggregation functions (COUNT, AVG, SUM) when necessary.\n",
        "      - If superlatives are mentioned (e.g., \"highest\"), use ORDER BY and LIMIT.\n",
        "      - Format the query with proper syntax.\n",
        "      - **Return only the SQL query.**\n",
        "      - Only use tables that are mentioned as relevant info OR in the info sql database tool.\n",
        "      - Also fluctuate the where clause generation of each query, by using \"LIKE '%word%'\" instead of \"= 'thisisalongword'.\n",
        "      - Also fluctuate the generation of each query, for between tables and without or without GROUP BY\n",
        "      - Use **different aggregation methods** (COUNT, SUM, AVG, etc.).\n",
        "      - Use if applicable **different order by methods** (ABS, ASC, DESC, etc.) if not mentioned vaguely in the prompt.\n",
        "      - Ensure syntax correctness before returning.\n",
        "      - **Return only the final SQL query**, without explanations.\n",
        "      - **Pay close attention to all requested columns in the user question.**\n",
        "      - **Use joins to combine data from multiple tables when necessary.**\n",
        "      - **Include all requested information in the query result, including school type, school name, and latitude.**\n",
        "      - **Use the correct table aliases (T1, T2, etc.) to avoid ambiguity when joining tables.**\n",
        "      - **If the question requests the \"highest\" or \"lowest\" value, use ORDER BY and LIMIT 1 to find the result.**\n",
        "      - **Use the correct column names from the tables, if the column names are slightly different from the question, use the column names from the tables.**\n",
        "      - **If the question asks for a specific \"type\" or \"category\", make sure to include the corresponding column in the SELECT statement.**\n",
        "      - **Return only the final SQL query**, without explanations.\n",
        "      \"\"\"\n",
        "      response = databasellm_agent.invoke(extended_prompt)\n",
        "      sql_blocks = re.findall(r\"```sql\\s*([\\s\\S]*?)\\s*```\", response['output'], re.MULTILINE)\n",
        "      query_in_list = [re.sub(r'\\s+', ' ', sql.strip()) for sql in sql_blocks]\n",
        "\n",
        "      global sql_query_store\n",
        "      sql_query_store.append(query_in_list)\n",
        "      # Validate by running the query with LIMIT 1\n",
        "      try:\n",
        "          db.run(f\"{query_in_list[0]} LIMIT 1\")\n",
        "          status = \"GOOD\"\n",
        "      except Exception as e:\n",
        "          status = \"NOT GOOD: \" + str(e)\n",
        "      good_results = execute_sql_query(extended_prompt, sql_query_store)\n",
        "      return good_results\n",
        "\n",
        "  manager_tools = [generate_sql_query_tool]\n",
        "\n",
        "  def execute_sql_query(extended_prompt: str, sql_query_store: list) -> list:\n",
        "    \"\"\"Executes SQL queries, separates good and bad, and uses refiner agent up to 3 times if needed.\"\"\"\n",
        "    good_queries = []\n",
        "    good_results = []\n",
        "\n",
        "    bad_queries = []\n",
        "    bad_results = []\n",
        "\n",
        "    global db\n",
        "    global refinerllm_agent\n",
        "\n",
        "    # print(\"sql_query_store\", sql_query_store)\n",
        "\n",
        "    # 1. First pass: Try all current queries\n",
        "    for query in sql_query_store[-1]:\n",
        "        optimized_query = limiting_queries(query)\n",
        "        try:\n",
        "            result = db.run(optimized_query)\n",
        "\n",
        "            #  Treat empty or suspicious results as failure\n",
        "            if not result or is_suspicious_result(query, result):\n",
        "                print(f\"Query returned suspicious result: {result}  retry or refine\")\n",
        "                raise Exception(f\"Query returned suspicious result: {result}  retry or refine\")\n",
        "\n",
        "            #  If we get a meaningful result, break the loop\n",
        "            if is_valid_result(result):  # <-- NEW check\n",
        "                print(f\" Query returned valid result: {result}\")\n",
        "                good_queries.append(optimized_query)\n",
        "                good_results.append(result)\n",
        "                break  #  STOP HERE\n",
        "\n",
        "            # Optional fallback if you're unsure about floats\n",
        "            print(f\" Query returned a non-empty but unconfirmed result: {result}\")\n",
        "            raise Exception(\"Unconfirmed result content\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" Query returned incorrect: {e}\")\n",
        "            bad_queries.append(optimized_query)\n",
        "            bad_results.append(f\"{str(e)}  refine\")\n",
        "\n",
        "    attempts = 3\n",
        "    # 2. If all failed, retry using the refiner agent (up to 3 times)\n",
        "    if not good_queries and refinerllm_agent is not None:\n",
        "        print(\"REFINER USED!!\")\n",
        "        for attempt in range(attempts):\n",
        "            # print(f\"\\n--- Refinement Attempt #{attempt + 1} ---\")\n",
        "            refine_input = extended_prompt\n",
        "\n",
        "            refine_input += \"\\n**Incorrect Queries:**\"\n",
        "            for i, query in enumerate(bad_queries):\n",
        "                refine_input += f\"\\n{i+1}: {query}\"\n",
        "\n",
        "            refine_input += \"\\n**Incorrect Results:**\"\n",
        "            for i, result in enumerate(bad_results):\n",
        "                refine_input += f\"\\n{i+1}: {result}\"\n",
        "\n",
        "            refine_input += \"\"\"\n",
        "- The query must be **structurally unique** (different FROM tables, joins, or filters).\n",
        "- Only use tables that are mentioned as relevant info OR in the info sql database tool.\n",
        "- **Analyze the error messages to identify the cause of the failures.**\n",
        "- **Use the schema information to ensure the corrected queries are valid.**\n",
        "- **Make minimal changes to the original queries to fix the errors.**\n",
        "- **Ensure the corrected query is valid against the database schema.**\n",
        "- **Avoid the error messages by using different tables and columns that caused the error messages.**\n",
        "- **Don't make the same query as either the good or bad queries.**\n",
        "- **Return only the final SQL query**, without explanations.\n",
        "\"\"\"\n",
        "\n",
        "            # print(\"Invoking refiner with input:\", refine_input)\n",
        "            response = refinerllm_agent.invoke(refine_input)\n",
        "\n",
        "            # Extract SQL from response\n",
        "            # print(\"Refiner response:\", response['output'])\n",
        "            sql_blocks = re.findall(r\"```sql\\s*([\\s\\S]*?)\\s*```\", response['output'], re.MULTILINE)\n",
        "            query_in_list = [re.sub(r'\\s+', ' ', sql.strip()) for sql in sql_blocks]\n",
        "\n",
        "            if not query_in_list:\n",
        "                print(\"No SQL query found in refiner output.\")\n",
        "                continue\n",
        "\n",
        "            extracted_sql_query = query_in_list[0]\n",
        "            optimized_refined_query = limiting_queries(extracted_sql_query)\n",
        "\n",
        "            try:\n",
        "                result = db.run(optimized_refined_query)\n",
        "                if result == '':\n",
        "                    raise Exception(\"Refined query returned empty result.\")\n",
        "                sql_query_store[-1].append(optimized_refined_query)\n",
        "                good_results.append(result)\n",
        "\n",
        "                print(\"Refined query succeeded.: \", sql_query_store[-1])\n",
        "                break  # Exit loop if successful\n",
        "            except Exception as e:\n",
        "                print(f\"Refined query attempt #{attempt+1} failed: {e}\")\n",
        "                bad_queries.append(optimized_refined_query)\n",
        "                bad_results.append(str(e))\n",
        "        return good_results\n",
        "    return good_results\n",
        "\n",
        "  prompt = \"\"\"\n",
        "  You are a SQL Manager Agent. Your job is to:\n",
        "  - Generate a valid SQL query in SQLite using the tool `generate_sql_query_tool`.\n",
        "  - Summarize the results from that query based on the user's question.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ##  STRICT RULES:\n",
        "\n",
        "  1. **ALWAYS call `generate_sql_query_tool` ONCE and ONLY ONCE.**\n",
        "  2. **NEVER call it again**, no matter the output.\n",
        "  3. The function `execute_sql_query` will handle validation. Your job is NOT to recheck or re-call the query.\n",
        "  4. You MUST stop after the first SQL tool call, even if:\n",
        "    - It returns an empty list\n",
        "    - It returns a failed or unexpected output\n",
        "    - You are unsure\n",
        "  5. ONLY return the final answer based on the result.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ##  Output Format:\n",
        "  - First, use `generate_sql_query_tool` ONCE.\n",
        "  - Then respond with a short, natural language answer using the results **you received** (assume it's valid unless explicitly told otherwise).\n",
        "  - NEVER call the tool again.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ##  Example:\n",
        "\n",
        "  User: \"How many employees work in each department?\"\n",
        "\n",
        "  You:\n",
        "  1. Call: `generate_sql_query_tool(\"SELECT department, COUNT(*) FROM employees GROUP BY department;\")`\n",
        "  2. Result: `[(\"Sales\", 45), (\"HR\", 10)]`\n",
        "  3. Answer: `\"The Sales department has the most employees (45), while HR has the least (10).\"`\n",
        "\n",
        "  ---\n",
        "\n",
        "  Remember:\n",
        "  - If the result is empty, say \"No results were found.\"\n",
        "  - If the result is invalid, say \"There was an error with the query.\"\n",
        "  - You NEVER fix or retry the SQL query. Just report.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  messages = [\n",
        "      prompt,\n",
        "      HumanMessagePromptTemplate.from_template(\"User Query: {input}\"),\n",
        "      AIMessage(content=SQL_FUNCTIONS_SUFFIX),\n",
        "      MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "  ]\n",
        "\n",
        "  manager_prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "  runnable = create_tool_calling_agent(managerllm, manager_tools, manager_prompt)  # type: ignore\n",
        "\n",
        "  agent = RunnableMultiActionAgent(\n",
        "      runnable=runnable,\n",
        "      input_keys_arg=[\"input\"],\n",
        "      return_keys_arg=[\"output\"]\n",
        "  )\n",
        "  manager_agent = AgentExecutor(\n",
        "      name=\"Manager Agent Executor\",\n",
        "      agent=agent,\n",
        "      tools=manager_tools,\n",
        "      verbose=True,\n",
        "      max_iterations=None,\n",
        "      max_execution_time=None,\n",
        "  )\n",
        "  print(\"Manager Agent created!\")\n",
        "  return manager_agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX8638-_wRhR"
      },
      "source": [
        "#### Configure Seniorllm Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAYhKOLuwcwo"
      },
      "outputs": [],
      "source": [
        "def configure_seniorllm():\n",
        "    @tool\n",
        "    def get_tables_columns_samples() -> str:\n",
        "        \"\"\"\n",
        "        Retrieves all available tables and their columns, ensuring all tables that could\n",
        "        be remotely related to the question are included.\n",
        "        \"\"\"\n",
        "        # print('3. Analyzing database schema...')\n",
        "        try:\n",
        "            table_names = \", \".join(db.get_usable_table_names())\n",
        "            table_info = db.get_table_info([t.strip() for t in table_names.split(\",\")])\n",
        "            return table_info\n",
        "        except Exception as e:\n",
        "            return f\"Error retrieving database schema: {str(e)}\"\n",
        "\n",
        "    seniorllm_tools = [get_tables_columns_samples]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a **Senior AI Database Analyst** with expert SQL knowledge.\n",
        "    Your role is to **identify ALL relevant tables and columns** that could possible help answer the question AND potentially try to explain any abbrevations.\n",
        "\n",
        "    ### **STRICT GUIDELINES**\n",
        "    - **MANDATORY**: Use available tools to retrieve the database schema.\n",
        "    - **NEVER** assume or invent tables/columns.\n",
        "    - **DO NOT** return just table namesalways include at least one relevant column per table.\n",
        "    - **ALWAYS** return every table that could possibly contribute to the answer, even if the relationship is indirect.\n",
        "    - **CROSS-REFERENCE** related tables (e.g., for sales: include `orders`, `orderdetails`, `payments`, not just `products`).\n",
        "    - **IF UNCERTAIN**, err on the side of including rather than excluding a table.\n",
        "\n",
        "    ### **HOW TO WORK**\n",
        "    1. Use `get_tables_columns_samples` to retrieve the full database schema.\n",
        "    2. Find and identify any possible related table(s) directly related to the question.\n",
        "    4. Provide an **explanation** of why each table is relevant.\n",
        "\n",
        "    ### **RESPONSE FORMAT**\n",
        "    - **Table  Relevant Columns**\n",
        "    - **Explanation of relevance**\n",
        "\n",
        "     Example:\n",
        "    **Tables:** `orders`, `orderdetails`, `payments`, `products`\n",
        "    **Relevant Columns:**\n",
        "    - `orderdetails`  `product_id`, `quantity` (Needed to track sold products)\n",
        "    - `orders`  `order_id`, `order_date` (Provides context on when sales happened)\n",
        "    - `payments`  `amount`, `payment_date` (Links revenue to sales)\n",
        "    - `products`  `product_id`, `expected_profit` (Identifies profitable products)\n",
        "    - `frpm`  `CDSCode` (The Free or Reduced-Price Meals table has a column named CDSCode which helps to identify the schools based on the reduced-price meals)\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        prompt,\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        "\n",
        "    seniorllm_prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "    runnable = create_tool_calling_agent(\n",
        "        seniorllm, seniorllm_tools, seniorllm_prompt\n",
        "    )  # type: ignore\n",
        "\n",
        "    agent = RunnableMultiActionAgent(\n",
        "        runnable=runnable, input_keys_arg=[\"input\"], return_keys_arg=[\"output\"]\n",
        "    )\n",
        "\n",
        "    seniorllm_agent = AgentExecutor(\n",
        "        name=\"SQL Agent Executor\",\n",
        "        agent=agent,\n",
        "        tools=seniorllm_tools,\n",
        "        verbose=False,\n",
        "        max_iterations=5,\n",
        "        max_execution_time=60,\n",
        "    )\n",
        "    print(\"Senior Agent created!\")\n",
        "    return seniorllm_agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s77J8e_bz5Mu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gahoBLU4B7VW"
      },
      "source": [
        "#### Configure refinerllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDhujLoUB7G6"
      },
      "outputs": [],
      "source": [
        "def configure_refinerllm(db: SQLDatabase, database_name: str, bucket_name: str, few_shot_path: str, refinerllm: Union[ChatOpenAI, ChatVertexAI], query_table_name='SQL'):\n",
        "  list_sql_database_tool = ListSQLDatabaseTool(db=db)\n",
        "\n",
        "  info_sql_database_tool_description = (\n",
        "      \"Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. \"\n",
        "      f\"Be sure that the tables actually exist by calling {list_sql_database_tool.name} first! \"\n",
        "      \"Example Input: table1, table2, table3\"\n",
        "  )\n",
        "  info_sql_database_tool = InfoSQLDatabaseTool(db=db, description=info_sql_database_tool_description)\n",
        "\n",
        "  query_sql_database_tool_description = (\n",
        "      \"Input to this tool is a detailed and correct SQL query, output is a \"\n",
        "      \"result from the database. If the query is not correct, an error message \"\n",
        "      \"will be returned. If an error is returned, rewrite the query, check the \"\n",
        "      \"query, and try again. If you encounter an issue with Unknown column \"\n",
        "      f\"'xxxx' in 'field list', use {info_sql_database_tool.name} \"\n",
        "      \"to query the correct table fields.\"\n",
        "  )\n",
        "  query_sql_database_tool = QuerySQLDataBaseTool(db=db, description=query_sql_database_tool_description)\n",
        "\n",
        "  refinerllm_tools = [\n",
        "      list_sql_database_tool,\n",
        "      info_sql_database_tool,\n",
        "      query_sql_database_tool,\n",
        "  ]\n",
        "\n",
        "  # Load training data from GCS\n",
        "  training_data = load_json_from_gcs(bucket_name, few_shot_path)\n",
        "\n",
        "  database_train = [entry for entry in training_data if entry.get(\"db_id\") == database_name]\n",
        "  few_shot_examples = \"\\n\".join(\n",
        "      [f\"Question: {ex['question']}\\nSQL: {ex[query_table_name]}\" for ex in database_train[:5]]\n",
        "  )\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "  You are an AI SQL agent specializing in generating and executing **syntactically correct SQL queries** in SQLite language.\n",
        "  Return a single final SQL querywithout explanations, reasoning, or extra textthat can be valid answers to the prompt.\n",
        "\n",
        "  ### **Database Knowledge**\n",
        "  Examples of correct queries based on the database structure:\n",
        "  {few_shot_examples}\n",
        "\n",
        "  ### **SQL Generation Rules**\n",
        "  - Before including any table in a SQL query, confirm its existence using `list_sql_database_tool`.\n",
        "  - If `query_sql_database_tool` returns an error indicating a table or column does not exist, use `info_sql_database_tool` to get the correct names and rewrite the query.\n",
        "  - When generating a query, follow these steps:\n",
        "      1. Use `list_sql_database_tool` to verify table existence.\n",
        "      2. If needed, use `info_sql_database_tool` to get table schema.\n",
        "      3. **Analyze the error messages from previous attempts to identify the specific tables and columns that caused errors. Avoid using these tables and columns in subsequent queries.**\n",
        "      4. Generate the SQL query using the error message information, and the schema information.\n",
        "      5. Use `query_sql_database_tool` to validate the query. If an error occurs, return to step 2.\n",
        "\n",
        "  ### **Tools Available**\n",
        "  Use the following tools as needed:\n",
        "  - `info_sql_database_tool`: Lists table names in the database.\n",
        "  - `query_sql_database_tool`: Execute SQL queries to valide. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use `info_sql_database_tool` to query the correct table fields\n",
        "\n",
        "  ### Abbreviation Handling\n",
        "  When you encounter abbreviations, follow these steps:\n",
        "  1.  Try to infer their full meaning from the surrounding context and the database schema.\n",
        "  2.  Pay close attention to column names and data types.\n",
        "  3.  Use the `info_sql_database_tool` to examine column data if needed.\n",
        "  4.  If unsure, reason about possible meanings based on the database context.\n",
        "\n",
        "  Example: If the question is 'Find schools with CDSCode 12345' and the database has a 'schools' table with a 'CDSCode' column, the SQL query should be 'SELECT * FROM schools WHERE CDSCode = '12345';' because CDSCode is a school identifier.\n",
        "\n",
        "  ### **Refinement Process**\n",
        "  You will be provided with a list of bad SQL queries that failed to execute, along with their corresponding error messages in a dictionary. Your task is to analyze these errors and generate corrected SQL queries that don't have tables and columns that cause errors as provided in the error messages.\n",
        "\n",
        "  ### **Error Analysis**\n",
        "  Common SQL errors include:\n",
        "  - \"unknown column\": The column name is incorrect.\n",
        "  - \"syntax error\": The SQL syntax is invalid.\n",
        "  - \"table not found\": The table name is incorrect.\n",
        "  - \"ambiguous column name\": a column name is used that exist in multiple tables, and the table is not specified.\n",
        "\n",
        "  ### **Input Format**\n",
        "  You will a prompt that will indicate the question/prompt, the failed queries (and which tables were incorrect used) and the correct queries.\n",
        "\n",
        "  ### **Refinement Rules**\n",
        "  - **Thoroughly analyze the error messages to identify the specific tables and columns that caused the errors.**\n",
        "  - **Avoid using tables and columns that caused previous errors.**\n",
        "  - If the results contain lots of NONE values, try to find the column that caused it and make a WHERE clause that says \"is not null\" like \"CharterNum is not null\"\n",
        "  - Use the `info_sql_database_tool` to get the correct schema information.\n",
        "  - **Make significant changes to the original query to fix the error, avoiding the use of the tables and columns that caused previous errors.**\n",
        "  - **Ensure the corrected query is significantly different from all previous attempts.**\n",
        "  - Ensure the corrected query is valid against the database schema.\n",
        "  - Avoid using Where clauses with exactly the correct phrase, rather use \"LIKE '%word%'\" instead of  \"= 'word'\" and look at the possible values in the column rather than the question. Example prompt: How many unified schools? -> LIKE '%unified school%'\n",
        "\n",
        "  ### **Response Format**\n",
        "  Your response **must only contain the final SQL query string**, without any explanation or reasoning.\n",
        "  \"\"\"\n",
        "\n",
        "  # databasellm_prompt = PromptTemplate(template=prompt, input_variables=[\"input\"])\n",
        "  messages = [prompt, HumanMessagePromptTemplate.from_template(\"{input}\"), AIMessage(content=SQL_FUNCTIONS_SUFFIX), MessagesPlaceholder(variable_name=\"agent_scratchpad\")]\n",
        "\n",
        "  refinerllm_prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "  runnable = create_tool_calling_agent(refinerllm, refinerllm_tools, refinerllm_prompt)  # type: ignore\n",
        "\n",
        "  agent = RunnableMultiActionAgent(runnable=runnable,input_keys_arg=[\"input\"], return_keys_arg=[\"output\"])\n",
        "\n",
        "  refinerllm_agent = AgentExecutor(\n",
        "          name=\"Refiner Agent Executor\",\n",
        "          agent=agent,\n",
        "          tools=refinerllm_tools,\n",
        "          verbose=False,\n",
        "          max_iterations=20,\n",
        "          max_execution_time=20,\n",
        "      )\n",
        "  print(\"Refiner Agent created!\")\n",
        "  return refinerllm_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APCnhgKhB7rF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubm0EHpulFk2"
      },
      "source": [
        "#### Extracting Training Equipment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcJ9v75Nm5zf"
      },
      "outputs": [],
      "source": [
        "def compute_sql_complexity(sql_query):\n",
        "    \"\"\"Computes complexity based on QSC, Parse Tree Depth, and Token Length.\"\"\"\n",
        "    parsed = sqlparse.parse(sql_query)\n",
        "\n",
        "    # 1. Query Token Length\n",
        "    token_length = len([t for t in parsed[0].tokens if t.value.strip()])\n",
        "\n",
        "    # 2. Query Structural Complexity (based on SQL keywords)\n",
        "    join_count = sql_query.upper().count(\"JOIN\")\n",
        "    agg_count = sum(sql_query.upper().count(kw) for kw in [\"COUNT\", \"SUM\", \"AVG\", \"MIN\", \"MAX\"])\n",
        "    filter_count = sql_query.upper().count(\"WHERE\")\n",
        "    order_count = sql_query.upper().count(\"ORDER BY\")\n",
        "    group_count = sql_query.upper().count(\"GROUP BY\")\n",
        "    having_count = sql_query.upper().count(\"HAVING\")\n",
        "\n",
        "    qsc_score = (2 * join_count) + (2 * agg_count) + filter_count + order_count + group_count + having_count\n",
        "\n",
        "    # 3. Parse Tree Depth (approximated by nested parentheses)\n",
        "    tree_depth = sql_query.count(\"(\")\n",
        "\n",
        "    return [qsc_score, tree_depth,token_length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsZk_TWfcIYZ"
      },
      "outputs": [],
      "source": [
        "def benchmarkingOnBirdBench(test_example, databasellm_agent, managerllm_agent, seniorllm_agent, refinerllm_agent, query_table_name, use_manager_agent=False, use_senior_agent=False, use_refiner_agent=False):\n",
        "  session_id = str(uuid.uuid4())\n",
        "  responses = []  # List to store all response data\n",
        "  last_sql_query_collection = None\n",
        "  for index, example in enumerate(test_example):\n",
        "      db_id = example[\"db_id\"]\n",
        "      question = example[\"question\"]\n",
        "      correct_sql = example[query_table_name]\n",
        "      try:\n",
        "        difficulty = example[\"difficulty\"]\n",
        "      except:\n",
        "        difficulty = \"medium\"\n",
        "      qsc_score, tree_depth, token_length = compute_sql_complexity(correct_sql)\n",
        "      # Create a dictionary to store response details\n",
        "      response_data = {\n",
        "          \"database_name\": db_id,\n",
        "          \"question_number\": index+1,\n",
        "          \"question\": question,\n",
        "          \"correct_sql\": correct_sql,\n",
        "          \"correct_answer\": None,\n",
        "          \"generated_output\": None,\n",
        "          \"generated_direct_output\": None,\n",
        "          \"response_status\": None,\n",
        "          \"iterations\": None, #optionally a way to calculate how many iterations the LLM made? To know the thinking process a bit\n",
        "          \"qsc_score\": qsc_score,\n",
        "          \"parse_tree_depth\": tree_depth,\n",
        "          \"token_length\": token_length,\n",
        "          \"difficulty\": difficulty,\n",
        "          \"time_spent\": None,\n",
        "          \"generated_query_runtime\": [],\n",
        "          \"correct_query_runtime\": None,\n",
        "      }\n",
        "      # Track start time for latency calculation & query storage\n",
        "      start_time = time.time()\n",
        "\n",
        "      # Execute the agent and get the response\n",
        "      print(\"Response calculating...\")\n",
        "      time_spent_start = time.time()\n",
        "      if not use_manager_agent: #using only database_agent\n",
        "        database_agent_prompt = f\"\"\"\n",
        "        Based on the following question, generate **a single** accurate SQL query given the prompt. **ALWAYS** assume that it is possible to answer the given question with given prompt information with the database.\n",
        "\n",
        "        **User Question:** {question}\n",
        "        - Only use tables that are mentioned as relevant info OR in the info sql database tool.\n",
        "        - Also fluctuate the where clause generation of each query, by using \"LIKE '%word%'\" instead of \"= 'thisisalongword'.\n",
        "        - Also fluctuate the generation of each query, for between tables and without or without GROUP BY\n",
        "        - Use **different aggregation methods** (COUNT, SUM, AVG, etc.).\n",
        "        - Use if applicable **different order by methods** (ABS, ASC, DESC, etc.) if not mentioned vaguely in the prompt.\n",
        "        - Ensure syntax correctness before returning.\n",
        "        - **Return only the final SQL query**, without explanations.\n",
        "        - **Pay close attention to all requested columns in the user question.**\n",
        "        - **Use joins to combine data from multiple tables when necessary.**\n",
        "        - **Include all requested information in the query result, including school type, school name, and latitude.**\n",
        "        - **Use the correct table aliases (T1, T2, etc.) to avoid ambiguity when joining tables.**\n",
        "        - **If the question requests the \"highest\" or \"lowest\" value, use ORDER BY and LIMIT 1 to find the result.**\n",
        "        - **Use the correct column names from the tables, if the column names are slightly different from the question, use the column names from the tables.**\n",
        "        - **If the question asks for a specific \"type\" or \"category\", make sure to include the corresponding column in the SELECT statement.**\n",
        "        - **Return only the final SQL query**, without explanations.\n",
        "        \"\"\"\n",
        "        response = databasellm_agent.invoke(database_agent_prompt)\n",
        "        sql_blocks = re.findall(r\"```sql\\s*([\\s\\S]*?)\\s*```\", response['output'], re.MULTILINE)\n",
        "        # Clean and format each SQL query\n",
        "        query_in_list = [re.sub(r'\\s+', ' ', sql.strip()) for sql in sql_blocks]\n",
        "      else:\n",
        "        response = managerllm_agent.invoke(question)\n",
        "        global sql_query_store\n",
        "        query_in_list = sql_query_store[-1]\n",
        "\n",
        "      response_data[\"time_spent\"] = time.time() - time_spent_start\n",
        "\n",
        "      generated_direct_outputs = []\n",
        "      for query in query_in_list:\n",
        "        try:\n",
        "          generated_query_start_time = time.time()\n",
        "          generated_direct_output = db.run(r\"{}\".format(query))\n",
        "          response_data[\"generated_query_runtime\"].append(time.time() - generated_query_start_time)\n",
        "        except Exception as e:\n",
        "          generated_direct_output = str(e)\n",
        "          response_data[\"generated_query_runtime\"].append(None)\n",
        "        generated_direct_outputs.append(generated_direct_output)\n",
        "\n",
        "      try:\n",
        "        correct_sql_start_time = time.time()\n",
        "        correct_answer = db.run(r\"{}\".format(correct_sql))\n",
        "        response_data[\"correct_query_runtime\"] = time.time() - correct_sql_start_time\n",
        "      except:\n",
        "        correct_answer = \"ANSWER IS INCORRECT: INVALID QUESTION\"\n",
        "        response_data[\"correct_query_runtime\"] = None\n",
        "\n",
        "      # Update response data\n",
        "      response_data.update({\n",
        "          \"generated_output\": response['output'], #change this to the response of toolcaller agent if enabled\n",
        "          \"generated_sqls\": query_in_list,\n",
        "          \"generated_direct_output\": [generated_direct_outputs], #change this for multi agents\n",
        "          \"correct_answer\": correct_answer,\n",
        "          \"response_status\": \"Success\",\n",
        "      })\n",
        "\n",
        "      # Debugging output\n",
        "      print(f\"  Question {index+1}: {question}\")\n",
        "      print(f\"> Generated Output: {response['output']}\")\n",
        "      print(f\"> Correct Output: {correct_answer}\")\n",
        "      print(f\"> Correct sql_query: {correct_sql}\")\n",
        "      print(f\"> Generated SQLs: {query_in_list}\")\n",
        "      print(f\"> Generated Direct Output: {generated_direct_outputs}\")\n",
        "      # print(f\"> Tokens Used: {response_data['tokens_used']}\")\n",
        "      print(f\"> Qsc_score: {qsc_score}\\n\")\n",
        "      responses.append(response_data)\n",
        "      print(f\"NEXT QUESTION!\")\n",
        "  return responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLAwAAmsLoPS"
      },
      "source": [
        "#### Benchmarking Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbZDDFaxFANe"
      },
      "source": [
        "##### Loading functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaDr8azE0ve7"
      },
      "outputs": [],
      "source": [
        "def load_json_from_gcs(bucket_name, blob_path):\n",
        "    \"\"\"Loads a JSON file from Google Cloud Storage.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_path)\n",
        "\n",
        "    try:\n",
        "        json_data = json.loads(blob.download_as_text())\n",
        "        return json_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON from GCS: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6Us78R30tS1"
      },
      "outputs": [],
      "source": [
        "def upload_json_to_gcs(bucket_name, blob_path, file_name, data):\n",
        "    \"\"\"Uploads JSON data to Google Cloud Storage.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob_path = os.path.join(output_folder, file_name)\n",
        "    blob = bucket.blob(blob_path)\n",
        "\n",
        "    try:\n",
        "        json_string = json.dumps(data, indent=4)\n",
        "        blob.upload_from_string(json_string, content_type=\"application/json\")\n",
        "        print(f\"JSON data uploaded to gs://{bucket_name}/{blob_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading JSON to GCS: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4J28WDtFC98"
      },
      "source": [
        "##### Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21_vLi5RgdnP"
      },
      "outputs": [],
      "source": [
        "# Store errors per session\n",
        "error_history_store = defaultdict(list)\n",
        "database_names = test_databases_names\n",
        "databases = test_databases\n",
        "dataset_folder = test_dataset_folder\n",
        "json_data = load_json_from_gcs(bucket_name, question_path)\n",
        "sql_query_store = []\n",
        "for database_name in database_names[1:]:\n",
        "  custom_prompts = [item for item in json_data if item.get('db_id') == database_name]\n",
        "  if len(custom_prompts) != 0:\n",
        "    print(f\"\"\"Database \"{database_name}\" contains {len(custom_prompts)} prompts\"\"\")\n",
        "    db = databases[database_name]\n",
        "\n",
        "    databasellm_agent, list_sql_database_tool, info_sql_database_tool = configure_databasellmv2(database_name, bucket_name, few_shot_path, few_shot_amount, query_amount, query_table_name)\n",
        "    if use_manager_agent:\n",
        "      if use_senior_agent:\n",
        "        seniorllm_agent = configure_seniorllm()\n",
        "      else:\n",
        "        seniorllm_agent = None\n",
        "      if use_refiner_agent:\n",
        "        refinerllm_agent = configure_refinerllm(db, database_name, bucket_name, few_shot_path, refinerllm, query_table_name)\n",
        "      else:\n",
        "        refinerllm_agent = None\n",
        "      managerllm_agent = create_manager_agentv3(databasellm_agent, seniorllm_agent, refinerllm_agent, list_sql_database_tool, info_sql_database_tool)\n",
        "    else:\n",
        "      managerllm_agent = None\n",
        "\n",
        "    responses = benchmarkingOnBirdBench(custom_prompts, databasellm_agent, managerllm_agent, seniorllm_agent, refinerllm_agent, query_table_name, use_manager_agent, use_senior_agent, use_refiner_agent)\n",
        "\n",
        "    output_file = f\"{database_name}_responses.json\"\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "      json.dump(responses, f, indent=4)\n",
        "\n",
        "    blob_path = os.path.join(output_folder, output_file)\n",
        "\n",
        "    upload_json_to_gcs(bucket_name, blob_path, output_file, responses)\n",
        "\n",
        "    # drive_output_file = \"/content/drive/MyDrive/Colab/benchmarks/bird-bench/geminiv5/\" + output_file\n",
        "    # with open(drive_output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    #   json.dump(responses, f, indent=4)\n",
        "\n",
        "    print(f\"\"\"Database \"{database_name}\" completed\\n\"\"\")\n",
        "  else:\n",
        "    print(f\"\"\"Database \"{database_name}\" has no prompts\\n\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HLEbhOsaC3G1",
        "OnRJukw4FOCN",
        "7ireR1GVC3HD",
        "oR4tGfAvC3Hk",
        "ubQ-AynmOndr",
        "b0P8zZzEkMVA",
        "eX8638-_wRhR",
        "gahoBLU4B7VW",
        "Ubm0EHpulFk2",
        "CbZDDFaxFANe"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}